{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criação orientada de amostra de treino #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Create a sample to train a model to identify extreme events\n",
    "\"\"\"\n",
    "\n",
    "from glass.fm.psql            import query_to_df\n",
    "from glass.gisp.pnd.mng       import split_df_inN\n",
    "from glass.gisp.psql.prop import get_row_number\n",
    "from glass.gisp.psql.mng.qw   import q_to_ntbl\n",
    "from glass.gisp.psql.mng      import tbls_to_tbl\n",
    "from glass.gisp.psql.mng._del import del_tables\n",
    "from glass.to.xls             import df_to_xls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Facedata\n",
    "\n",
    "CON_PGSQL = {\n",
    "    \"HOST\" : \"localhost\", \"PORT\" : \"5432\", \"DATABASE\" : \"dsn_collect\",\n",
    "    \"USER\" : \"postgres\", \"PASSWORD\" : \"admin\", \"TEMPLATE\" : \"postgis_template\"\n",
    "}\n",
    "\n",
    "WORD_SCHEMA = {\n",
    "    \"TNAME\" : \"search_words\",\n",
    "    \"WORD\"  : \"word\"\n",
    "}\n",
    "\n",
    "DATA_SCHEMA = {\n",
    "    \"TNAME\"      : (\n",
    "        \"(\"\n",
    "        \"SELECT post_id, \"\n",
    "        \"CASE WHEN type = 'link' THEN description ELSE message END AS message, \"\n",
    "        \"type, link, datahora, page_ref FROM facedata\"\n",
    "        \") AS foo\"\n",
    "    ),\n",
    "    \"FID\"        : \"post_id\",\n",
    "    \"TEXT_COL\"   : \"message\",\n",
    "    \"TIME\"       : \"datahora\",\n",
    "    \"OTHER_COLS\" : [\"type\", \"page_ref\"],\n",
    "    \"LOWER_TIME\" : \"2017-05-31 23:59:59\",\n",
    "    \"HIGH_TIME\"  : \"2019-01-01 00:00:00\"\n",
    "}\n",
    "\n",
    "SPLIT_IN = 10\n",
    "\n",
    "OUTFILE = r'D:\\gis\\GEOTIMELINE\\DSN_Collector\\train_sample_facebook.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Twitter\n",
    "\n",
    "CON_PGSQL = {\n",
    "    \"HOST\" : \"localhost\", \"PORT\" : \"5432\", \"DATABASE\" : \"dsn_collect\",\n",
    "    \"USER\" : \"postgres\", \"PASSWORD\" : \"admin\", \"TEMPLATE\" : \"postgis_template\"\n",
    "}\n",
    "\n",
    "WORD_SCHEMA = {\n",
    "    \"TNAME\" : \"search_words\",\n",
    "    \"WORD\"  : \"word\"\n",
    "}\n",
    "\n",
    "DATA_SCHEMA = {\n",
    "    \"TNAME\"      : \"twitter_data\",\n",
    "    \"TEXT_COL\"   : \"text\",\n",
    "    \"TIME\"       : \"tweet_time\",\n",
    "    \"FID\"        : \"fid\",\n",
    "    \"OTHER_COLS\" : [\"keyword\"],\n",
    "    \"LOWER_TIME\" : \"2018-08-31 23:59:59\",\n",
    "    \"HIGH_TIME\"  : \"2019-01-01 00:00:00\"\n",
    "}\n",
    "\n",
    "SPLIT_IN = 10\n",
    "\n",
    "OUTFILE = r'D:\\gis\\GEOTIMELINE\\DSN_Collector\\train_twitter.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get words\n",
    "\n",
    "wordsInterest = query_to_df(CON_PGSQL, \"SELECT {} FROM {}\".format(\n",
    "    WORD_SCHEMA[\"WORD\"], WORD_SCHEMA[\"TNAME\"]\n",
    "))[WORD_SCHEMA[\"WORD\"]].tolist()\n",
    "\n",
    "print wordsInterest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get sample table for each word\n",
    "\n",
    "w = 1\n",
    "TABLES = []\n",
    "\n",
    "__TBL = (\"(\"\n",
    "    \"SELECT * FROM {t} \"\n",
    "    \"WHERE TO_TIMESTAMP({timeCol}, 'YYYY-MM-DD HH24:MI:SS') > \"\n",
    "    \"TO_TIMESTAMP('{lowerTime}', 'YYYY-MM-DD HH24:MI:SS') AND \"\n",
    "    \"TO_TIMESTAMP({timeCol}, 'YYYY-MM-DD HH24:MI:SS') < \"\n",
    "    \"TO_TIMESTAMP('{highTime}', 'YYYY-MM-DD HH24:MI:SS')\"\n",
    "\") AS jtbl\").format(\n",
    "    timeCol=DATA_SCHEMA[\"TIME\"],\n",
    "    lowerTime=DATA_SCHEMA[\"LOWER_TIME\"],\n",
    "    highTime=DATA_SCHEMA[\"HIGH_TIME\"],\n",
    "    t=DATA_SCHEMA[\"TNAME\"]\n",
    ")\n",
    "    \n",
    "for word in wordsInterest:\n",
    "    ntbl = q_to_ntbl(CON_PGSQL, \"data_{}\".format(w), (\n",
    "        \"SELECT {fidCol} \"\n",
    "        \"FROM {tbl} WHERE {txtc} LIKE '%{w}%'\"\n",
    "    ).format(\n",
    "        tbl=__TBL, txtc=DATA_SCHEMA[\"TEXT_COL\"],\n",
    "        w=word, fidCol=DATA_SCHEMA[\"FID\"]\n",
    "    ))\n",
    "    \n",
    "    TABLES.append(ntbl)\n",
    "    w += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_TBL = tbls_to_tbl(CON_PGSQL, TABLES, \"sample_tbl_tmp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NROWS_sample = get_row_number(CON_PGSQL, SAMPLE_TBL)\n",
    "\n",
    "NROWS30 = int((30*NROWS_sample) / 100.0)\n",
    "print NROWS_sample\n",
    "print NROWS30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = (\n",
    "    \"SELECT REPLACE(REPLACE(REPLACE(regexp_replace(\"\n",
    "        \"REPLACE(REPLACE(REPLACE(regexp_replace(\"\n",
    "        \"{txtCol}, 'https://[^:\\s]+(\\S+)', '', 'g'), ' ', 'XXX'), '.', 'YYY'), \"\n",
    "        \"'-', 'ZZZ'), '[^\\w+]', '', 'g'), 'XXX', ' '), 'YYY', '.'), \"\n",
    "        \"'ZZZ', '-') AS {txtCol}, \"\n",
    "    \"{timeCol}, {fidCol}, {ocols} FROM (\"\n",
    "        \"SELECT jtbl.{txtCol}, jtbl.{timeCol}, jtbl.{fidCol}, {otherCols}, \"\n",
    "        \"row_number() OVER(PARTITION BY mtbl.{fidCol} ORDER BY mtbl.{fidCol}) \"\n",
    "        \"AS count_row FROM {sample_tbl} AS mtbl FULL JOIN {o_tbl} \"\n",
    "        \"ON mtbl.{fidCol} = jtbl.{fidCol}\"\n",
    "    \") AS foo WHERE count_row < {trinta}\"\n",
    ").format(\n",
    "    txtCol=DATA_SCHEMA[\"TEXT_COL\"], timeCol=DATA_SCHEMA[\"TIME\"],\n",
    "    fidCol=DATA_SCHEMA[\"FID\"], ocols=\", \".join(DATA_SCHEMA[\"OTHER_COLS\"]),\n",
    "    otherCols=\", \".join([\"jtbl.{}\".format(c) for c in DATA_SCHEMA[\"OTHER_COLS\"]]),\n",
    "    sample_tbl=SAMPLE_TBL, o_tbl =__TBL,\n",
    "    trinta = str(NROWS30)\n",
    ")\n",
    "\n",
    "REAL_SAMPLE_TBL = q_to_ntbl(CON_PGSQL, \"sample_tbl_real\", Q)\n",
    "\n",
    "NROWS_check = get_row_number(CON_PGSQL, REAL_SAMPLE_TBL)\n",
    "\n",
    "print NROWS_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export data\n",
    "\n",
    "DATA_SCHEMA[\"OTHER_COLS\"].append(DATA_SCHEMA[\"FID\"])\n",
    "\n",
    "dataDf = query_to_df(CON_PGSQL, (\n",
    "    \"SELECT {txtCol}, {otherCols}, \"\n",
    "    \"to_char(MIN(TO_TIMESTAMP({timeCol}, 'YYYY-MM-DD HH24:MI:SS')), \"\n",
    "        \"'YYYY-MM-DD HH24:MI:SS') AS {timeCol} \"\n",
    "    \"FROM {tbl} WHERE {txtCol} <> '' AND {txtCol} <> ' ' \"\n",
    "    \"GROUP BY {txtCol}\"\n",
    ").format(\n",
    "    txtCol = DATA_SCHEMA[\"TEXT_COL\"],\n",
    "    otherCols = \", \".join([(\n",
    "        \"REPLACE(REPLACE(CAST(array_agg({a} ORDER BY \"\n",
    "        \"{b}) AS text), '{{', ''), '}}', '') AS {a}\"\n",
    "    ).format(\n",
    "        a=DATA_SCHEMA[\"OTHER_COLS\"][x],\n",
    "        b=DATA_SCHEMA[\"OTHER_COLS\"][0]\n",
    "    ) for x in range(len(DATA_SCHEMA[\"OTHER_COLS\"]))]),\n",
    "    timeCol=DATA_SCHEMA[\"TIME\"],\n",
    "    tbl=REAL_SAMPLE_TBL\n",
    "))\n",
    "\n",
    "dfParts = split_df_inN(dataDf, SPLIT_IN)\n",
    "\n",
    "df_to_xls(dfParts, OUTFILE, sheetsName=[\"sample_{}\".format(i) for i in range(len(dfParts))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del_tables(CON_PGSQL, TABLES + [SAMPLE_TBL, REAL_SAMPLE_TBL])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del_tables(CON_PGSQL, TABLES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criação não orientada de uma amostra de treino #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Twitter\n",
    "\n",
    "CON_PGSQL = {\n",
    "    \"HOST\" : \"localhost\", \"PORT\" : \"5432\", \"DATABASE\" : \"dsn_collect\",\n",
    "    \"USER\" : \"postgres\", \"PASSWORD\" : \"admin\", \"TEMPLATE\" : \"postgis_template\"\n",
    "}\n",
    "\n",
    "WORD_SCHEMA = {\n",
    "    \"TNAME\" : \"search_words\",\n",
    "    \"WORD\"  : \"word\"\n",
    "}\n",
    "\n",
    "DATA_SCHEMA = {\n",
    "    \"TNAME\"      : \"twitter_data\",\n",
    "    \"TEXT_COL\"   : \"text\",\n",
    "    \"TIME\"       : \"tweet_time\",\n",
    "    \"OTHER_COLS\" : [\"fid\", \"username\", \"keyword\"],\n",
    "    \"LOWER_TIME\" : \"2017-05-31 23:59:59\",\n",
    "    \"HIGH_TIME\"  : \"2019-01-01 00:00:00\"\n",
    "}\n",
    "\n",
    "SPLIT_IN = 10\n",
    "\n",
    "OUTFILE = r'D:\\gis\\GEOTIMELINE\\DSN_Collector\\train_sample_twitter.xlsx'\n",
    "\n",
    "from glass.fm.psql import query_to_df\n",
    "from glass.to.xls  import df_to_xls\n",
    "from glass.gisp.pnd.mng import split_df_inN\n",
    "\n",
    "# Export data\n",
    "\n",
    "dataDf = query_to_df(CON_PGSQL, (\n",
    "    \"SELECT {santxtCol} AS {txtCol}, {otherCols}, \"\n",
    "    \"to_char(MIN(TO_TIMESTAMP({timeCol}, 'YYYY-MM-DD HH24:MI:SS')), 'YYYY-MM-DD HH24:MI:SS') \"\n",
    "    \"FROM {tbl} WHERE {txtCol} <> '' AND {txtCol} <> ' ' AND \"\n",
    "    \"TO_TIMESTAMP({timeCol}, 'YYYY-MM-DD HH24:MI:SS') > TO_TIMESTAMP('{ltime}', 'YYYY-MM-DD HH24:MI:SS') \"\n",
    "    \"AND TO_TIMESTAMP({timeCol}, 'YYYY-MM-DD HH24:MI:SS') < \"\n",
    "    \"TO_TIMESTAMP('{htime}', 'YYYY-MM-DD HH24:MI:SS') \"\n",
    "    \"GROUP BY {txtCol}\"\n",
    ").format(\n",
    "    santxtCol=(\n",
    "        \"REPLACE(REPLACE(REPLACE(regexp_replace(\"\n",
    "        \"REPLACE(REPLACE(REPLACE(regexp_replace(\"\n",
    "        \"{}, 'https://[^:\\s]+(\\S+)', '', 'g'), ' ', 'XXX'), '.', 'YYY'), \"\n",
    "        \"'-', 'ZZZ'), '[^\\w+]', '', 'g'), 'XXX', ' '), 'YYY', '.'), \"\n",
    "        \"'ZZZ', '-')\"\n",
    "    ).format(DATA_SCHEMA[\"TEXT_COL\"]),\n",
    "    txtCol = DATA_SCHEMA[\"TEXT_COL\"],\n",
    "    otherCols = \", \".join([(\n",
    "        \"REPLACE(REPLACE(CAST(array_agg({a} ORDER BY \"\n",
    "        \"{b}) AS text), '{{', ''), '}}', '') AS {a}\"\n",
    "    ).format(\n",
    "        a=DATA_SCHEMA[\"OTHER_COLS\"][x],\n",
    "        b=DATA_SCHEMA[\"OTHER_COLS\"][0]\n",
    "    ) for x in range(len(DATA_SCHEMA[\"OTHER_COLS\"]))]),\n",
    "    timeCol=DATA_SCHEMA[\"TIME\"],\n",
    "    ltime=DATA_SCHEMA[\"LOWER_TIME\"], htime=DATA_SCHEMA[\"HIGH_TIME\"],\n",
    "    tbl=DATA_SCHEMA[\"TNAME\"]\n",
    "))\n",
    "\n",
    "dfParts = split_df_inN(dataDf, SPLIT_IN)\n",
    "\n",
    "df_to_xls(dfParts, OUTFILE, sheetsName=[\"sample_{}\".format(i) for i in range(len(dfParts))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
